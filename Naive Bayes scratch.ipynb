{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Naive Bayes algorithm from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all the essential packages and libararies along with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "df = data.data\n",
    "y = data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y,  test_size = 0.3, random_state =42)\n",
    "log_reg = LogisticRegression(solver = 'liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset into training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "    return math.sqrt(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(x_train, y_train):\n",
    "    separated_mal = []\n",
    "    separated_ben = []\n",
    "    for j in range(len(x_train)):\n",
    "        if (y_train[j] == 0):\n",
    "            separated_mal.append(x_train[j])\n",
    "        else:\n",
    "            separated_ben.append(x_train[j])\n",
    "    return separated_mal, separated_ben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separting the malignant and benign data and applying data handling on those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the probablity of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateClassProbabilities(summaries, input_1):\n",
    "    probabilities = 1\n",
    "    for i in range(len(summaries)):\n",
    "        mean, stdev = summaries[i]\n",
    "        x = input_1[i]\n",
    "        probabilities *= calculateProbability(x, mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(x_train):\n",
    "    summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*x_train)]\n",
    "    return summaries\n",
    " \n",
    "def summarizeByClass(x_train, y_train):\n",
    "    separated_mal, separated_ben = separateByClass(x_train, y_train)\n",
    "    summary_mal = summarize(separated_mal)\n",
    "    summary_ben = summarize(separated_ben)\n",
    "    return summary_mal, summary_ben \n",
    "\n",
    "summary_mal, summary_ben = summarizeByClass(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(x_test):\n",
    "    predictions = []\n",
    "    for i in range(len(x_test)):\n",
    "        mal_pro = calculateClassProbabilities(summary_mal, x_test[i])\n",
    "        ben_pro = calculateClassProbabilities(summary_ben, x_test[i])\n",
    "        if mal_pro > ben_pro:\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predictions = getPredictions(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_predictions[i] == y_test[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(y_test))) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy using the Naive Bayes algorithm is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.56725146198829"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAccuracy(y_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result using Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Metrics\n",
      "Accuracy Score :\t0.9649\n",
      "Recall Score :\t\t0.9815\n",
      "Precision Score :\t0.9636\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(x_train, y_train)\n",
    "log_reg.score(x_train,y_train)\n",
    "log_pred = log_reg.predict(x_test)\n",
    "confusion_matrix(y_test,log_pred)\n",
    "print('Test Data Metrics')\n",
    "print ('Accuracy Score :\\t{:.4}'.format(accuracy_score(y_test,log_pred)))\n",
    "print ('Recall Score :\\t\\t{:.4}'.format(recall_score(y_test,log_pred)))\n",
    "print ('Precision Score :\\t{:.4}'.format(precision_score(y_test,log_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy using Logistic Regression came out to be 96.49%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Logistic Regression has a better prediction than NB with probability of 96.49% which is significantly higher than 63.15%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
